`ThreadCache` 是内存池的顶层，为每个线程提供快速、无锁的内存分配与回收，其实现细节与其他层差不多，故本篇只说值得注意的获取与回收策略
```cpp
#include "../../include/TCMalloc/ThreadCache.h"
#include"../../include/TCMalloc/CentralCache.h"
#include "../../include/TCMalloc/TCMallocutils.h"
#include <assert.h>
namespace mystl
{
	std::optional<void*> thread_cache::allocate(size_t memory_size)
	{
		if (memory_size == 0)
		{
			return std::nullopt;
		}

		//对齐到8字节
		memory_size = size_utils::align(memory_size);
		if (memory_size > size_utils::MAX_CACHED_UNIT_SIZE) {
			auto result = allocate_from_central_cache(memory_size);
			if (result) {
				return std::optional<void*>(result->data());
			}
			else {
				return std::nullopt; 
			}
		}

		const size_t index = size_utils::get_index(memory_size);
		if (!m_free_cache[index].empty())
		{
			auto result = m_free_cache[index].front();
			m_free_cache[index].pop_front();
			assert(result.size() == memory_size);
			return result.data();
		}
		auto result = allocate_from_central_cache(memory_size);
		if (result) {
			return std::optional<void*>(result->data());
		}
		else {
			return std::nullopt;
		}
	}

	void thread_cache::deallocate(void* start_p, size_t memory_size)
	{
		if (memory_size == 0) {
			return;
		}
		memory_size = size_utils::align(memory_size);
		span<byte> memory(static_cast<byte*>(start_p), memory_size);
		// 如果大于了最大缓存值了，说明是直接从中心缓存区申请的，可以直接返还给中心缓存区
		if (memory_size > size_utils::MAX_CACHED_UNIT_SIZE) {
			list<span<byte>> free_list;
			free_list.push_back(memory);
			central_cache::get_instance().deallocate(std::move(free_list));
			return;
		}
		const size_t index = size_utils::get_index(memory_size);
		m_free_cache[index].push_front(memory);

		// 检测一下需不需要回收
		// 如果当前的列表所维护的大小已经超过了阈值，则触发资源回收
		// 维护的大小 = 个数 × 单个空间的大小
		if (m_free_cache[index].size() * memory_size > MAX_FREE_BYTES_PER_LISTS) {
			// 如果超过了，则回收一半的多余的内存块
			size_t deallocate_block_size = m_free_cache[index].size() / 2;
			list<span<byte>> memory_to_deallocate;
			auto middle = m_free_cache[index].begin();
			advance(middle, deallocate_block_size);
			memory_to_deallocate.splice(memory_to_deallocate.begin(), m_free_cache[index], middle, m_free_cache[index].end());
			central_cache::get_instance().deallocate(std::move(memory_to_deallocate));
			// 在回收工作完成以后，还要调整这个空间大小的申请的个数
			// 减半下一次申请的个数
			m_next_allocate_count[index] /= 2;
		}
	}

	std::optional<span<byte>> thread_cache::allocate_from_central_cache(size_t memory_size) {
		size_t block_count = compute_allocate_count(memory_size);
		auto allocation_result = central_cache::get_instance().allocate(memory_size, block_count);
		if (allocation_result)
		{
			auto memory_list = move(allocation_result.value());

			span<byte> result = memory_list.front();
			assert(result.size() == memory_size);
			memory_list.pop_front();
			const size_t index = size_utils::get_index(memory_size);

			m_free_cache[index].splice(m_free_cache[index].end(), memory_list);

			return result;
		}
		else
		{
			return std::nullopt;
		}
	}

	size_t thread_cache::compute_allocate_count(size_t memory_size) {
		// 获取其下标
		size_t index = size_utils::get_index(memory_size);

		if (index >= size_utils::CACHE_LINE_SIZE) {
			return 1;
		}

		// 最少申请4个块
		size_t result = std::max(m_next_allocate_count[index], static_cast<size_t>(4));


		// 计算下一次要申请的个数，默认乘2
		size_t next_allocate_count = result * 2;
		// 要确保不会超过center_cache一次申请的最大个数
		next_allocate_count = std::min(next_allocate_count, page_span::MAX_UNIT_COUNT);
		// 同时也要确保不会超过一个列表维护的最大容量
		// 比如16KB的内存块，不能一次性申请128个吧
		// 256 * 1024 B / 16 * 1024 B / 2 = 8个（这里就将16KB的内存一次性最多申请8个，要给点冗余(除2)，不然可能会反复申请）
		next_allocate_count = std::min(next_allocate_count, MAX_FREE_BYTES_PER_LISTS / memory_size / 2);
		// 更新下一次要申请的个数
		m_next_allocate_count[index] = next_allocate_count;
		// 返回这一次申请的个数
		return result;
	}
}

```
# 小内存获取和回收策略 

## 获取策略
每次进行获取的前提条件是自由链表为空或大小不够满足申请需求，需要从 `CentralCache` 批量获取内存来填充本地缓存，并从中取出一块返回

每次向 `CentralCache` 获取的块数是动态的，取的是 `m_next_allocate_count` 中记录的值和**最小值4**之间的较大者。

同时每次申请后会为**下一次**申请做准，将本次的 `m_next_allocate_count` 中记录的值**翻倍**

为了防止申请数量无限增长，这个翻倍后的新值会受到两个上限的限制：
- 不能超过 `page_span::MAX_UNIT_COUNT` (512)，即单个内存页最多切分的块数
- 不能一次性申请超过该尺寸自由链表总容量一半的内存块

## 回收策略
*对于常规大小的内存，它会被直接添加到 `m_free_cache` 中对应尺寸的自由链表的头部

而在添加完回收的内存块后，函数会检查当前自由链表的总大小（`链表长度 × 块大小`）是否超过了阈值 `MAX_FREE_BYTES_PER_LISTS` (256KB)
- 如果超过阈值，`ThreadCache` 会将该链表中**一半**的内存块通过 `list::splice` 高效地移动到一个临时列表中，并调用 `central_cache::get_instance().deallocate` 将它们归还给中心缓存

**动态调整**：作为一种自适应“惩罚”机制，在回收完成后，对应尺寸的 `m_next_allocate_count` 的值会被**减半**，以减少未来对该尺寸内存的批量申请数量

