# 并发编程的必要性
与以往不同，我们首先对于多线程环境下的标准库 `new/delete` 进行测试，来查看它的速度

| 测试项                 | 线程数 (nworks) | 轮次 (rounds) | 单轮操作数 (ntimes) | 总计花费 (ms) |
| ------------------- | ------------ | ----------- | -------------- | --------- |
| 标准 `new` / `delete` | 100          | 100         | 1000           | 4311908   |
| 标准 `new` / `delete` | 1            | 10000       | 1000           | 3892      |

可以看出在总体的操作数不变的情况下，它们的差距是巨大的
这是因为在多线程环境下：
- 标准库的 `new` / `delete` 为了保证线程安全，通常会使用一个**全局的互斥锁**。所有并发的内存分配和释放请求，都必须通过这个锁来串行化
- 这导致了严重的**锁竞争**。大多数线程会花大量时间**排队等待这个全局锁**，而不是执行实际的工作。这个全局锁成为了一个巨大的性能瓶颈，使得总耗时急剧增加

所以急需对于线程池进行相对细颗粒度的并行编程处理，下面我们使用**最简单的**互斥量 `mutex` 进行简单处理
# 使用互斥量
在原本的 `HashBucketMemoryPool` 的版本上加上基础的互斥量 `mutex` 来实现简单的线程安全
## 定义部分
需要在 `SimpleMemoryPool` 类中新增两个互斥量的定义
```cpp
class SimpleMemoryPool
{
	//其余部分相同
private:
	size_t				BlockSize_;
	size_t				SlotSize_;
	SimpleSlot*			firstBlock_;
	char*				curSlot_;
	SimpleSlot*			freeList_;
	char*				lastSlot_;
	std::mutex			mutexForFreeList_;//保证freeList_在多线程中操作的原子性
	std::mutex			mutexForBlock_;//保证多线程情况下避免不必要的重复开辟内存导致的浪费行为
};
```
其中新增的互斥量的作用分别是：
- **`mutexForFreeList_`**：用于保证 `freeList` 在多线程中操作的原子性，使得一个槽不会被同时分配给两个申请
- **`mutexForBlock_;`**：用于保证多线程情况下不会同时调用多次 `allocateNewBlock`，出现不必要的重复开辟内存行为（且有可能会导致块内存的泄漏）

## 实现部分
围绕着两个新增的互斥量，我们需要在在**多线程情况下可能发生竞争的地方**加入互斥量
### 竞争域分析

| 竞争类型 | 受影响资源                           | 潜在后果         |
| ---- | ------------------------------- | ------------ |
| 数据竞争 | 空闲链表指针(`freeList_`)             | 链表断裂/ABA问题   |
| 状态争用 | 内存块分配位置(`curSlot_`)             | 内存块重复分配或位置覆盖 |
| 资源冲突 | 新内存块分配操作 (`allocateNewBlock()`) | 内存泄漏或链接丢失    |
对于这些资源的修改与访问都发生在 `allocate` 与 `deallocate` 下，故对其进行修改
### `allocate ()`
```cpp
void* SimpleMemoryPool::allocate()
{
	if (SlotSize_ == 0) {
		std::cerr << "Error: SimpleMemoryPool::init() not called or slotSize is 0! Exiting." << std::endl;
		exit(1);
	}

	{
		std::lock_guard<std::mutex> lock(mutexForFreeList_);
		if (freeList_ != nullptr)
		{
			SimpleSlot* slot = popFreeList();
			return slot;
		}
	}//使用括号限制锁的生命周期


	{
		std::lock_guard<std::mutex> lock(mutexForBlock_);
		if (curSlot_ == nullptr || (curSlot_ + SlotSize_) > lastSlot_)
		{
			allocateNewBlock();
		}


		if ((curSlot_ + SlotSize_) <= lastSlot_)
		{
			void* slot = curSlot_;
			curSlot_ += SlotSize_;
			return slot;
		}
		else
		{
			std::cerr << "Error: Fresh block allocated but cannot fit a slot! Check BlockSize/SlotSize. Exiting." << std::endl;
			exit(1);
		}
	}
}
```
使用了 `std::lock_guard` 来保护不同的竞争区域
- `mutexForFreeList_` 保护了 `freeList_` 非空时的 `popFreeList()` 操作
- `mutexForBlock_` 保护了 `curSlot_` 的检查和 `allocateNewBlock()` 的调用
值得注意的是使用了 `{}` 来明确锁的生命周期，减少锁的持有时间，从而减少不同操作之间的锁竞争

### `deallocate()`
```cpp
void SimpleMemoryPool::deallocate(void* ptr) {
	if (ptr == nullptr) return;

	std::lock_guard<std::mutex>lock(mutexForFreeList_);
	SimpleSlot* slot = static_cast<SimpleSlot*>(ptr);

	pushFreeList(slot);
}
```

## 测试

| 测试项                    | 线程数 (nworks) | 轮次 (rounds) | 单轮操作数 (ntimes) | 总计花费 (ms) |
| ---------------------- | ------------ | ----------- | -------------- | --------- |
| 标准 `new`/`delete`      | 100          | 100         | 1000           | 4396312   |
| `HashBucketMemoryPool` | 100          | 100         | 1000           | 1214066   |
目前我们加入了互斥量的 `HashBucketMemoryPool` 在此高并发场景下，比标准 `new` / `delete` **快了大约 3.6 倍** 

## 局限性
### 锁的开销
- **上下文切换**：当一个线程尝试获取已被占用的互斥量时，它会**被阻塞**，操作系统会**将其从 CPU 上调度走**，并调度另一个线程运行。这个过程称为**上下文切换**，它是一个相对**昂贵**的操作
- **内核态/用户态切换**：获取和释放互斥量通常涉及操作系统内核的参与，这会从用户态切换到内核态，带来额外的开销
- **缓存线反弹**：在**高竞争**的锁上，不同 CPU 核心频繁地请求同一个锁的缓存线，**导致缓存线在核心间来回传递**，这会显著降低性能

### 可伸缩性限制
- 互斥量通过**串行化**对共享资源的访问来保证线程安全。这意味着，即使你的系统有再多的 CPU 核心，访问被同一个互斥量保护的临界区时，仍然是**一次只能有一个线程**
- 随着并发线程数的增加，互斥量会成为一个**中心化的瓶颈**。线程越多，排队等待锁的时间就越长，程序的性能提升就会趋于平缓甚至下降，无法充分利用多核 CPU 的潜力

### 引入复杂性及潜在的并发错误
- 虽然我们的内存池中并没有这部分内容的出现，但是在日常编程中使用了互斥量容易出现死锁、活锁、优先级反转等问题


为了在**极端高并发场景**下实现更极致的性能，并避免互斥量带来的上述局限性（特别是锁的开销和可伸缩性限制），引入**无锁数据结构**进行优化

# 无锁数据结构
锁数据结构是一种在并发编程中设计**数据结构**的方法，其核心思想是**在不使用传统互斥锁的情况下，保证共享数据在多线程环境下的正确性**

我们选择使用基于原子操作的无锁队列来代替原有使用互斥锁的实现
## 无锁队列
无锁队列是指在多线程环境中，其入队和出队操作无需使用互斥锁就能保证正确性，并且在任意时刻，**至少有一个线程能够取得进展**（即**非阻塞性**）
### 核心概念
- **原子操作**：无锁队列的基石。它们是不可分割的操作，确保在多线程环境下，对**共享变量**的读写、修改是瞬间完成的，不会被其他线程中断。C++11 提供了 `std::atomic` 模板类来支持这些操作
- **比较并交换（Compare-And-Swap, CAS）**：这是实现复杂无锁算法最常见的原子原语。CAS 操作通常接收三个参数：一个内存地址、一个期望值、一个新值。如果内存地址当前的值等于期望值，则原子地将其更新为新值。否则，操作失败
- 在 C++ 中，`std::atomic` 提供了 `compare_exchange_weak()` 和 `compare_exchange_strong()` 方法来实现 CAS


## 为什么选择无锁队列
在内存池中，最频繁的竞争点就是**空闲链表 `freeList_` 的入队和出队操作**。将这两个操作无锁化，可以显著提升并发性能


## 实现
### 移除互斥量
用于 `freeList_` 的互斥量 `mutexForFreeList_` 可以丢弃掉了，但用于块分配的互斥锁 `mutexForBlock` 仍然保留，因为这是较少发生的操作
### 修改 `Slot` 结构，使用原子指针
若简单使用
```cpp
struct atomicSlot
{
	std::atomic<atomicSlot*> next;
};
```
在 `pushFreeList` 和 `popFreeList` 的CAS 操作中容易出现 **ABA 问题**


这是**最经典**的问题
假设线程 A 读取 `next` 指针为 `P`
在线程 A 尝试执行 CAS 操作之前，线程 B 将 `P` 从链表中移除并释放，然后又重新分配了内存，并且这个新分配的内存地址碰巧也是 `P`（由于 `freeList_` 的存在，这是非常可能的），并将其重新插入链表
此时，线程 A 再次检查 `next` 指针，发现它仍然是 `P`，所以**认为链表没有被修改**，从而成功执行 CAS
然而，实际上 `P` 已经不是原来的那个 `P` 了，这可能导致数据结构损坏或**逻辑错误**


为了尽可能避免 ABA 问题，使用带版本号的 `Slot` 来加强 CAS 比较的条件

```cpp
struct SimpleSlot
{
	SimpleSlot* next;
};
struct TagAtomicSlot
{
	SimpleSlot* ptr;
	unsigned int tag;
	// 填充字节，确保 TagAtomicSlot 总大小是 16 字节 (在 64 位系统上)
	// 64位系统: ptr (8字节) + tag (4字节) + 4字节填充 = 16字节
	char padding[4];

	bool operator==(const TagAtomicSlot& other)const
	{
		return ptr == other.ptr && tag == other.tag;
	}
	bool operator!=(const TagAtomicSlot& other)const
	{
		return !(*this == other);
	}
};
```
注意此时我们使用的 `TagAtomicSlot` 拥有
- 一个链表指针 `ptr` 
- 一个 `tag`（版本号/计数器）。

这个 `tag` 的作用是在每次对 `TagAtomicSlot` 进行修改时（例如，在 `pushFreeList` 或 `popFreeList` 中更新链表头部），都将其值**递增**. 这样，即使 `ptr` 回到了一个旧的内存地址 `P`，其关联的 `tag` 值也会是不同的

在 CAS 操作中，`compare_exchange_weak` (或 `compare_exchange_strong`) 会同时比较 `ptr` 和 `tag`。只有当两者都与预期的 `oldHead` 值完全匹配时，CAS 操作才会成功. 如果 `ptr` 相同但 `tag` 不同，CAS 就会失败，从而指示操作者重新尝试，**有效避免**了 ABA 问题

填充字节 `char padding[4]` 的目的是确保 `TagAtomicSlot` 的总大小在 64 位系统上是 16 字节，实现内存对齐

而操作的原子性保证放在了链表上
```cpp
std::atomic<TagAtomicSlot>	freeList_;
```
这确保了对链表头部的修改是原子的，并且 `ptr` 和 `tag` 的更新是同步进行的


### 修改入队与出队操作实现，实现 CAS 操作
#### 入队操作
```cpp
//实现无锁入队操作
bool SimpleMemoryPool::pushFreeList(SimpleSlot* slot) {
	TagAtomicSlot oldHead;
	while (true)
	{
		//获取当前头节点
		oldHead = freeList_.load(std::memory_order_relaxed);
		//将新节点的next指向当前头节点
		slot->next=oldHead.ptr;

		//尝试将新节点设置为头节点
		if (freeList_.compare_exchange_weak(oldHead,{slot,oldHead.tag+1}, std::memory_order_release, std::memory_order_relaxed))
		{
			return true;
		}
		//CAS失败则重试
	}
}
```
核心的 CAS 操作：
- 将 `freeList_` 的当前值与 `oldHead` 进行比较
- 如果它们相等（即在读取 `oldHead` 和执行 CAS 之间，没有其他线程修改 `freeList_`），则原子地将 `freeList_` 的值更新为 `{slot, oldHead.tag + 1}`
- **`std::memory_order_release`**: 如果 CAS 成功，这确保在当前线程中，所有在 `pushFreeList` 之前发生的内存写入（例如，对 `slot` 内数据的初始化）都在 `freeList_` 更新操作完成之前完成，并且对其他线程是可见的
- **`std::memory_order_relaxed`**: 如果 CAS 失败，则使用 `relaxed` 序。因为失败意味着没有发生状态改变，只是重新尝试，所以不需要强内存序
- 如果 CAS 成功，函数返回 `true`
- 如果 CAS 失败，循环会继续，重新读取 `freeList_` 的最新状态并再次尝试

出队的 CAS 操作的原理也一致
#### 出队操作
```cpp
//实现无锁出队操作
SimpleSlot* SimpleMemoryPool::popFreeList() {
	TagAtomicSlot oldHead;
	SimpleSlot* result_slot = nullptr;
	while (true)
	{
		oldHead = freeList_.load(std::memory_order_relaxed);
		if (oldHead.ptr== nullptr)
		{
			return nullptr;//队列为空
		}

		// 获取下一个节点 (普通指针)
		SimpleSlot* newHead = oldHead.ptr->next;

		if (freeList_.compare_exchange_weak(oldHead, { newHead, oldHead.tag + 1 },std::memory_order_release, std::memory_order_relaxed)) 
		{
			result_slot = oldHead.ptr;
			break;
		}
	}
	return result_slot;
}
```


## 测试
| 测试项                  | 线程数 (nworks) | 轮次 (rounds) | 单轮操作数 (ntimes) | 总计花费 (ms) |
| -------------------- | ------------ | ----------- | -------------- | --------- |
| 标准 `new`/`delete`    | 100          | 100         | 1000           | 4396312   |
| `MutexMemoryPool`    | 100          | 100         | 1000           | 1214066   |
| `ListFreeMemoryPool` | 100          | 100         | 1000           | 5796798   |
即使在注释掉了大量的有关分配失败的错误的输出提示后（之前的实现基本不输出），花费的时间仍然非常高
## 原因分析 
 - **极高竞争下的自旋开销：
	- 无锁算法，尤其是基于 CAS 的算法，在 CAS 失败时会进入自旋重试循环 (`while(true)` ).
	- 当多个线程同时尝试修改 `freeList_` 时，只有一个线程的 CAS 操作会成功，其余线程的 CAS 会失败. 这些失败的线程会立即重试，形成一个“**忙等**”状态
	- **缓存行颠簸**：每次 CAS 失败并重试时，都需要重新读取 `freeList_` 所在的缓存行。由于 `freeList_` 是共享的 `std::atomic<TagAtomicSlot>`，它**被多个核心频繁地尝试读写**，导致 `freeList_` 所在的缓存行在不同 CPU 核心之间**频繁地无效化和传输**。这个过程称为缓存行颠簸，会消耗大量的总线带宽和 CPU 周期，从而极大地降低整体性能
	- 这种自旋和缓存颠簸的开销在高竞争下甚至可能超过传统互斥锁的上下文切换开销。互斥锁在竞争激烈时会让等待的线程休眠，从而释放 CPU 资源并减少缓存竞争
- **缺乏线程局部性缓存**：
	- `ListFreeMemoryPool` 的 `pushFreeList` 和 `popFreeList` 操作都直接作用于**全局共享**的 `freeList_`. 这意味着每个分配和释放请求，即使在低竞争时期，也必须通过原子操作来修改这个共享变量
	- **原子操作本身的开销**：虽然原子操作**避免了互斥锁的上下文切换**，但它们本身并不是“免费”的


# 优化方向
实现分层缓存解决自旋开销和线程局限性的问题


